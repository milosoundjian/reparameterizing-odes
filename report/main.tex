\documentclass[oneside, a4paper, onecolumn, 11pt]{article}

% Change this: Customize the title, author, advisor, abstract
\newcommand{\thesistitle}[0]{Reparametrizing ODE models by scaling}
\newcommand{\authorname}[0]{Milos Oundjian}

\newcommand{\supervisor}[0]{Gleb Pogudin}
\newcommand{\supervisorinstitution}[0]{LIX}

\newcommand{\abstracttext}[0]{
    In this thesis, we present a novel implementation of the Hubert and Labahn algorithm for scaling invariants and symmetry reduction in dynamical systems, utilizing the Julia programming language. Our work extends the algorithm's application to non-identifiable models, offering a tool for the simplification and analysis of complex ordinary differential equation (ODE) models prevalent in the natural sciences. By integrating this implementation with the ``StructuralIdentifiability.jl'' package, we aim to make it easier for scientist to access this algorithm, enabling researchers without extensive computational backgrounds to leverage model simplification and reparameterization techniques. This approach not only facilitates the numerical solution of intricate models but also contributes to a deeper understanding of the underlying principles governing natural phenomena.
}

\usepackage[
    left=2cm,top=2.0cm,bottom=2.0cm,right=2cm,
    headheight=17pt, % as per the warning by fancyhdr
    includehead,includefoot,
    heightrounded, % to avoid spurious underfull messages
]{geometry}

% Added package
\usepackage[utf8]{inputenc}

% Template packages
\usepackage[T1]{fontenc}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{enumerate}
\usepackage{paralist}
\usepackage{xspace}
\usepackage{xcolor}
% Replace obsolete times package with mathptmx
% \usepackage{times}
\usepackage{mathptmx}
\usepackage[colorlinks, linkcolor=blue]{hyperref}
\setlength {\marginparwidth}{2.0cm}
\usepackage{pdfpages}
\usepackage{fancyhdr} %% For changing headers and footers
\usepackage{titling}
\usepackage[nottoc, numbib]{tocbibind}

% Added packages
\usepackage[framemethod=tikz]{mdframed} % For better box in abstract
\usepackage{esdiff} % For differentials
\usepackage{enumitem} % For step by step methodology
\usepackage{float} % For putting images properly
\usepackage{mathdots} % For having \iddots
\usepackage[ruled,vlined,linesnumbered]{algorithm2e} % For algorithms
\usepackage{listings}

% Commands
\newcommand{\Z}[0]{\mathbb{Z}}
\newcommand{\Zn}[1]{\mathbb{Z}^{#1}}
\newcommand{\Zmn}[2]{\mathbb{Z}^{#1 \times #2}}

\newcommand{\todo}[1]{
    \begin{mdframed}
        \textcolor{orange}{
        TODO: #1
        }
    \end{mdframed}
}

\newtheorem{definition}{Definition}
\newenvironment{example}[1][Example]{\textbf{#1.} }{\medskip}

\begin{document}

\hspace{0pt}
\vfill

\begin{center}
    \includegraphics[width=0.3\textwidth]{logo-EP-vertical}
    \vspace*{2em}

    {\large
        \textbf{\'Ecole Polytechnique}
        \vspace*{1em}

        \textit{BACHELOR THESIS IN COMPUTER SCIENCE}
        \vspace*{3em}

        {\Huge \textbf{\thesistitle}}
        \vspace*{3em}

        \textit{Author:}
        \vspace*{1em}

        \authorname{}, \'Ecole Polytechnique
        \vspace*{2em}

        {\textit{Advisor:}}
        \vspace*{1em}

        \supervisor{}, \supervisorinstitution{}
    }
    \vspace*{2em}

    \textit{Academic year 2023/2024}
\end{center}

\vfill
\hspace{0pt}

\newpage

\noindent\textbf{Abstract}

\begin{mdframed}
    \abstracttext{}
\end{mdframed}

\newpage

% Setting up the header
\pagestyle{fancy}
%\renewcommand{\headrulewidth}{0pt} % Remove line at top
%\renewcommand{\headrulewidth}{0.4pt}% Default \headrulewidth is 0.4pt
\lhead{\authorname}
%\chead{\acronym}
\rhead{\thesistitle}

\newpage
\tableofcontents
\newpage

% \pagenumbering{arabic}

\section{Background}

\subsection{Julia Programming Language}

The Julia programming language, introduced in 2012, is a high-level, high-performance language designed for technical and scientific computing. It is designed to combine the usability of python with the speed and efficiency of C \cite{bezanson2017julia}. It is well suited for symbolic computation such as operations with polynomials and matrices thanks to sophisticated mathematical syntax, dynamic typing, and extensive support for numerical operations. Furthermore, libraries such as Nemo.jl make it easy to have access to ecosystems of packages that can all work together to make going from theoretical math to algorithms in code much simpler.

\subsection{Nemo}

The Nemo package for Julia is designed to support work in commutative algebra and number theory, providing tools for arithmetic operations, polynomial manipulations, and matrix computations \cite{nemo}. It leverages the Flint library to offer efficient arithmetic capabilities. Nemo is valuable for researchers and mathematicians needing high-performance computational tools. Its integration with Julia enhances its appeal by combining Flint's arithmetic efficiency with Julia's high-level syntax and performance, making it a practical choice for computational mathematics projects, including the StructuralIdentifiability package.

\subsection{StructuralIdentifiability}

StructuralIdentifiability.jl is a package developed for the Julia programming language, designed to evaluate whether parameters within parametric Ordinary Differential Equation (ODE) models can be uniquely determined, covering both local and global perspectives. It facilitates the calculation of functions that can identify states and parameters. Additionally, the package provides tools for analyzing local identifiability in models based on discrete time. It serves as an introductory resource for understanding structural identifiability.

\newpage

\section{Introduction}

In their paper ``Scaling Invariants and Symmetry Reductions of Dynamical Systems'' \cite{Hubert2013}, they discuss the theory behind the algorithm and how it can be implemented. The algorithm is based on an extension of the Buckingham-\(\pi\)-theorem to enable a systematic algorithm to find the invariants that the Buckingham-\(\pi\)-theorem describes but does not tell us how to obtain.

The algorithm is described in the paper but no implementation of it exists. Thus the goal of this paper is to create an implementation of this algorithm in Julia.

Some obstacles to the implementation of this algorithm were that while libraries existed for getting Hermite Normal Forms, they only existed for \textit{row} Hermite Normal Form and not Column Hermite Normal forms, so it was necessary to create a function to do this and to prove its accuracy. This is detailed in section \ref{algo-hnf}.

An additional goal of this paper is to possibly add the implemented algorithm into the Julia library StructuralIdentifiability \cite{structidjl} to make it accessible to scientists in the fields of Biology and Chemistry who are working with Ordinary Differential Equations that can make use of reparameterization to make them easier to solve.

\section{Background}

\subsection{Hermite Normal Forms and Hermite Multipliers}

The algorithm described in \cite{Hubert2013} extensively uses Hermite Normal Forms and what it calls ``Hermite Multipliers''. So this section will go over the definitions that are used in that paper and here in order to avoid potential errors over notation since different notations for Hermite Normal Forms exist from different authors.

\subsubsection{Hermite Normal Forms (HNFs)}

While different sources may have varying definitions of Hermite Normal Forms, the ones we will follow are from \cite{Hubert2013} as they are the ones used in the definition of the algorithm.

\begin{definition}[\textit{Column} Hermite Normal Form]
    \begin{enumerate}[label=(\roman*)]
        \item The first \(r\) columns are non-zero;
        \item \(h_{k, j} = 0\) for \(k > i_j\);
        \item \(0 \le h_{i_j, k} < h_{i_j, j}\) when \(j < k\).
    \end{enumerate}
\end{definition}

\begin{definition}[\textit{Row} Hermite Normal Form]
    \begin{enumerate}[label=(\roman*)]
        \item The first \(r\) rows are non-zero;
        \item \(h_{i, k} = 0\) for \(k < j_i\);
        \item \(0 \le h_{k, j_i} < h_{i, j_i}\) when \(i < k\).
    \end{enumerate}
\end{definition}

% TODO: Fix the formatting for the definitions.

\begin{example}
    Take for example the matrix
    \[
        \begin{pmatrix}
            6 & 0 & -4 & 1  & 3 \\
            4 & 3 & 1  & -4 & 3
        \end{pmatrix}.
    \]

    The \textit{row} Hermite Normal Form of this matrix is
    \[
        \begin{pmatrix}
            2 & 6 & 6  & -9  & 3 \\
            0 & 9 & 11 & -14 & 3
        \end{pmatrix}.
    \]

    The \textit{column} Hermite Normal Form of this matrix is
    \[
        \begin{pmatrix}
            1 & 0 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 & 0
        \end{pmatrix}.
    \]
\end{example}

While they may seem similar, it is important to be careful since both of these forms are used in the algorithm, thus in this paper we will try to always be specific about which Hermite Normal Form we are using.

\subsubsection{Hermite Multipliers}

Any integer matrix \(A\) can be transformed via integer row operations (respectively column) to obtain a unique row (respectively column) Hermite Normal Form matrix H. We can encode these row operations (respectively column) into a unimodular integer matrix \(V\) such that we have \(V \cdot A = H\) (respectively \(A \cdot V = H\)). This matrix V is sometimes called the Hermite transform. In this paper we will be following \cite{Hubert2013} and calling in the \textit{Hermite Multiplier} of \(A\).

\begin{example}
    Again let us take the matrix
    \[
        A = \begin{pmatrix}
            6 & 0 & -4 & 1  & 3 \\
            4 & 3 & 1  & -4 & 3
        \end{pmatrix}.
    \]

    Its \textit{column} Hermite Normal Form is:
    \[
        H = \begin{pmatrix}
            1 & 0 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 & 0
        \end{pmatrix}.
    \]

    And a Hermite Multiplier is
    \[
        V = \begin{pmatrix}
            16  & 4  & 6   & 33  & -60 \\
            -28 & -7 & -11 & -58 & 105 \\
            24  & 6  & 9   & 50  & -90 \\
            1   & 0  & 0   & 2   & -3  \\
            0   & 0  & 0   & 0   & 1
        \end{pmatrix}.
    \]

    We can check that \(A \cdot V = H\).
\end{example}


\subsubsection{Algorithmically determining HNF and Hermite Multipliers} \label{algo-hnf}

There exists algorithms that can computer Hermite Normal Forms which can be found for example in \cite{cohen2013course}. The steps and complexity of this algorithm is discussed there as well. However, for the scope of this paper we will not discuss these algorithms in detail.

Effectively, we will use these algorithms as a part of our algorithm. To do this we give this algorithm a specification. The function we care about is in the Julia library \texttt{Nemo.jl} \cite{nemo} and is called \texttt{hnf\_with\_transform}. The specification of this function is as follows:

This means that in our algorithm, we already have a tool that allows us to calculate row Hermite Normal Form. What we need to do is to find a way to use this tool, for example by doing matrix operations on the input matrix \(A\) and on the result from using the function \texttt{hnf\_with\_transform} to be able to create a new function that taking input matrix \(A\), returns the column hermite normal form of \(A\). In the next section we will show how we are able to do this and prove our new method.

\newpage

\begin{algorithm}[H]
    \caption{hnf\_with\_transform\_column}

    \begin{description}
        \item[Input] Integer matrix \(A\)
        \item[Output] \textit{column} HNF matrix \(H\) and Hermite Multiplier \(V\)
    \end{description}

    \begin{enumerate}[label = \textbf{(Step~\arabic*)}, leftmargin=*, align=left, labelsep=2pt, itemsep=0pt]
        \item Set \(m\) the number of rows of matrix \(A\) and \(r\) its rank.
        \item Reverse the rows of \(A\) then transpose \(A\).
        \item Set \(H\) and \(V\) to be the \textit{row} HNF and corresponding multiplier of \(A\).
        \item Transpose \(H\), then reverse the rows of \(H\), then reverse the first \(r\) columns of \(H\).
        \item Transpose \(V\), then reverse the rows of \(V\).
        \item Return \(H\) our \textit{column} Hermite Normal Form of the input \(A\) and \(V\) the corresponding Hermite Multiplier.
    \end{enumerate}
\end{algorithm}

The \texttt{hnf\_with\_transform} function that the Nemo library provides us with works to get the \textit{row} Hermite Normal Form of our input matrix \(A\) by doing row operations. This is due to the property of the Hermite Normal Form being found through a series of row operations on the input matrix \(A\). Similarly, the \textit{column} Hermite Normal can be found through series of column operations, so transposing \(A\) applying the \texttt{hnf\_with\_transform} and then transposing the result will allow us to effectively be using column operations (Row operations on the transpose are like column operations on the original matrix).

There are a few more details to this algorithm that are elaborated on in the next section.

\subsubsection{Explanation and Proof of Algorithm}

We start with a matrix \(A \in \Zmn{m}{n}\) of rank \(r\). We start by reversing the rows of \(A\), which is equivalent to multiplying \(A\) on the left my the \(m \times m\) matrix. The reason we do this is that later on in the algorithm we will have to reverse the rows again in order to get the proper \textit{column} Hermite Normal Form layout for the result matrix, so we have to flip the rows once in advance to cancel out the effect.
\[
    C_m = \begin{pmatrix}
        0      & \cdots  & 1      \\
        \vdots & \iddots & \vdots \\
        1      & \cdots  & 0
    \end{pmatrix}
\]
So we get the result of \(C_m A\). We then take the transpose of this to get:
\[
    (C_m A)^\intercal = A^\intercal C_m
\]

We then get the Hermite Normal Form and Hermite Multiplier of this, this is done through a series of row operations on the \(A^\intercal C_m\). We use the Nemo function \texttt{hnf\_with\_transform(A)} to do this which, gives us \(H\) the \textit{row} Hermite Normal Form of \(A\) and \(V\) a Hermite Multiplier. Thus applying this to \(A^\intercal C_m\), we get \(H\) and \(V\) such that:
\[
    V \cdot (A^\intercal C_m) = H
\]

Furthermore, since \(H\) is in \textit{row} Hermite Normal Form, we have that it follows the definition, and thus as a matrix looks something like this:
\[
    H = \left(
    \begin{array}{ccccc}
            * & \cdot & | & |      & \cdot \\
            0 & 0     & * & |      & \cdot \\
            0 & 0     & 0 & *      & \cdot \\
            0 & 0     & 0 & \cdots & 0     \\
            0 & 0     & 0 & \cdots & 0
        \end{array}
    \right)
\]

Where non first \(r\) columns are \(0\), and the \(|\) symbols show values that are \(0 \le | \le *\) To follow conditions (ii) and (iii).

Now we need to change \(H\) so that it is in \textit{column} Hermite Normal Form according to our definition and so that \(A \cdot V = H\).

To do this our next step is to take the transpose of \(H\). Taking this our new \(H^\intercal\) looks like this.
\[
    H^\intercal = \left(
    \begin{array}{ccccc}
            *     & 0     & 0     & 0      & 0      \\
            \cdot & 0     & 0     & 0      & 0      \\
            -     & *     & 0     & 0      & 0      \\
            -     & -     & *     & \vdots & \vdots \\
            \cdot & \cdot & \cdot & 0      & 0      \\
        \end{array}
    \right)
\]

We then bring flip the rows again giving us:
\[
    C_m H^\intercal = \left(
    \begin{array}{ccccc}
            \cdot & \cdot & \cdot & 0      & 0      \\
            -     & -     & *     & 0      & 0      \\
            -     & *     & 0     & 0      & 0      \\
            \cdot & 0     & 0     & \vdots & \vdots \\
            *     & 0     & 0     & 0      & 0      \\
        \end{array}
    \right)
\]

The final step is to flip the first \(r\) columns of the resulting \(C_m H^\intercal\) to get:
\[
    C_m H^\intercal C_r = \left(
    \begin{array}{ccccc}
            \cdot & \cdot & \cdot & 0      & 0      \\
            *     & -     & -     & 0      & \vdots \\
            0     & *     & -     & 0      & 0      \\
            0     & 0     & \cdot & \vdots & \vdots \\
            0     & 0     & *     & 0      & 0      \\
        \end{array}
    \right)
\]

This final result is in \textit{column} Hermite Normal Form according to our definition, so thus we have our desired result.

From the linear algebra perspective, what we did holds up. From what we had earlier:
\begin{align*}
    V \cdot (A^\intercal C_m)             & = H                   \\
    (V \cdot (A^\intercal) C_m)^\intercal & = H^\intercal         \\
    C_m A \cdot V^\intercal               & = H^\intercal         \\
    A \cdot V^\intercal C_r               & = C_m H^\intercal C_r \\
\end{align*}

We note that in our algorithm applied transpose and multiplication on the right by \(C_r\) so our resulting \(V\) is \(V^\intercal C_r\) from the original \(V\) we had from our \texttt{hnf\_with\_transform(A)} function.

It is very clear to see how it uses the steps of our algorithm to get the \textit{column} Hermite Normal Form.

\subsubsection{Normal Hermite Multiplier}

As explained earlier, the Hermite Normal Form of an integer matrix is unique, however the Hermite Multiplier itself is not. In section 2.2 of \cite{Hubert2013}, they describe a way to calculate the \textit{row} Hermite Normal Form Normal Hermite Multiplier through making a change to the input matrix \(A\). Proposition 2.3 in the paper defines the Normal Hermite Multiplier and provides the algorithm.

This algorithm was implemented in Julia for this project. The implementation is as follows.

\hfill\break

\begin{algorithm}[H]
    \caption{hnf\_with\_normal\_transform\_column}

    \begin{description}
        \item[Input] Integer matrix \(A\)
        \item[Output] \textit{column} HNF matrix \(H\) and \textit{Normal} Hermite Multiplier \(V\)
    \end{description}

    \begin{enumerate}[label = \textbf{(Step~\arabic*)}, leftmargin=*, align=left, labelsep=2pt, itemsep=0pt]
        \item Set \(H\) to be the \textit{column} Hermite Normal Form of \(A\).
        \item Set \(r\) and \(n\) to be the number of rows and columns of \(A\) respectively.
        \item Set \(B\) to be A with an \(n \times n\) identity matrix on top, aka \(B = \begin{bmatrix} I_n \\ A \end{bmatrix}\).
        \item Set \(H^*\) and\textit{row} Hermite Normal Form of \(B\).
        \item Set \(V_i\) to be the last \(r\) columns of \(H^*\) with the bottom \(r\) rows removed.
        \item Set \(V_n\) to be the first \(n - r\) columns of with the bottom \(r\) rows removed.
        \item Set \(V = \begin{bmatrix} V_i & V_n \end{bmatrix}\).
        \item Return \(H\) and \(V\).
    \end{enumerate}
\end{algorithm}

\section{Algorithm}

Now that we have a way to calculate the \textit{column} Hermite Normal Forms and \textit{column} Normal Hermite Transforms, we finally have all the tools to implement the algorithm to simplify the ODE equations. The proofs of the algorithm are explained in \cite{Hubert2013} so this paper is not going to go over them. However, we will be going over each part of the algorithm with examples to demonstrate how it comes together in order to reparameterize ODEs.

The clearest way to illustrate this algorithm is with a diagram. The diagram below illustrates the steps of the algorithm that will be elaborated in the next section with examples.

\newpage

% TODO: Make this diagram nice

\begin{figure}[H]
    \centering
    \includegraphics{images/Algo.pdf}
    % \caption{Enter Caption}
    % \label{fig:enter-label}
\end{figure}

\newpage

\section{Implementation}

The following section explains how this algorithm was implemented in practice with an example.

\subsection{Transformation of ODEs into Matrix Form}

The initial phase in the reparameterization of ordinary differential equations (ODEs) pivots on the foundational step of converting our system of ODEs into a structured format amenable to manipulation and analysis. This process begins by reformatting the system into a matrix representation, which facilitates the application of algebraic and computational techniques for further examination and transformation.

In the context of our implementation, we leverage the `StructuralIdentifiability' \cite{structidjl} package in Julia, a tool for symbolic computation, made for for analyzing the identifiability of parameters within systems described by ODEs. This package offers a structured approach to defining ODEs, incorporating essential elements such as variables \texttt{x\_vars}, parameters, and the independent variable \texttt{t}. This structured definition not only standardizes the representation of differential equations but also simplifies the extraction and manipulation of their components.

The transformation process is as follows:

\begin{enumerate}
    \item \textbf{Definition of the ODE System:} Utilizing the \texttt{@ODEmodel} macro provided by the `StructuralIdentifiability' package, we can easily define in Julia a system of ODEs. We can access the equations of this ODE through the \texttt{x\_equations} field and the parameters through the \texttt{x\_vars} and \texttt{parameters}. In many real life experimental scenarios, the user may also want to designate certain parameters as measured quantities, which in the ODE are designated as output values in the field \texttt{y\_vars}.

    \item \textbf{Extraction and Parsing of Equations:} With the system defined, the next step involves extracting each equation and parsing them to isolate the numerator and denominator. This step is crucial for handling fractional equations, which are common in biological and physical systems modeling. The parsing process ensures that each equation is represented in a fractional form (including non-fractional ones by treating the denominator as just 1), facilitating uniform treatment in later stages. We then use a custom function \texttt{vector\_to\_matrix} in order to get the result in the Nemo integer matrices that are easier to work with than the lists of vectors that we get from the equation.

    \item \textbf{Normalizing} Following the algorithm \cite{Hubert2013}, we now have to normalize each equations. This means that we assure that at least one term in the denominator is a constant. This is equivalent to one of the rows in the denominator matrix being zero. So the way we implement this in our algorithm is to take whatever the first row in our denominator is and to subtract it from all the other rows in the numerator and the denominator. This is analogous to dividing by that term in both the numerator and the denominator, which does not change the value of the polynomial.

    \item \textbf{Padding of Matrix} Due to the independent variable \texttt{t} not being extracted, we need to account for it by adding a new column at the end of our resulting matrix. This can be seen in the algorithm in \cite{Hubert2013} as the matrices K always have a row for the independent variable (usually \texttt{t}).

    \item \textbf{Concatenation} We combine the resulting matrices into one matrix that is our resulting matrix. We then transpose the result to get a matrix following the convention followed in \cite{Hubert2013}.
\end{enumerate}

We can illustrate this process with this example.

Let us start with the Predator Prey Model:
\begin{align*}
    \diff{n}{t}
     & = n (r (1 - \frac{n}{K} - k \frac{p}{n + d})), \\
    \diff{p}{t}
     & = sp (1 - h \frac{p}{n})
\end{align*}

In our `StructuralIdentifiability' \texttt{@ODEmodel} struct, we will be interested in three fields. \texttt{x\_vars}, \texttt{parameters} and \texttt{x\_equations}. In this example \texttt{x\_vars} is the vector containing \texttt{n(t)} and \texttt{p(t)}, \texttt{parameters} is the vector containing \texttt{K, d, h, k, r, s}, \texttt{x\_equations} is a dictionary mapping \texttt{x\_vars} to the corresponding equation for it in the ODE.

With that in mind we start by extracting a list of the equations. In this example giving us a list like this:
\begin{lstlisting}
2-element Vector{AbstractAlgebra.Generic.FracFieldElem{QQMPolyRingElem}}:
(-n(t)^3*r + n(t)^2*K*r - n(t)^2*d*r - 
n(t)*p(t)*K*k*r + n(t)*K*d*r)//(n(t)*K + K*d)
(n(t)*p(t)*s - p(t)^2*h*s)//n(t)
\end{lstlisting}

The comes the `parsing' process, where we turn the equations into tuples of numerator and denominator matrices. We handle non fractional equations by turning them into fractional equations by setting the denominator to 1. We then concert the result into Nemo ZZMatrices that will be easier to work with. At this stage we are left with a series of matrices. In our example we get
\begin{lstlisting}
2-element Vector{Tuple{ZZMatrix, ZZMatrix}}:
([0 0 0 0 1 0 3 0; 1 0 0 0 1 0 2 0; 0 1 0 0 1 0 2 0; 1 0 0 1 1 0 1 1; 1 1 0 0 1 0 1 0], [1 0 0 0 0 0 1 0; 1 1 0 0 0 0 0 0])
([0 0 0 0 0 1 1 1; 0 0 1 0 0 1 0 2], [0 0 0 0 0 0 1 0])
\end{lstlisting}
% TODO: Maybe convert this into full matrix form

The order of the variables here is the \texttt{parameters} field elements followed by \texttt{x\_vars}  field elements.

We then have to take into account the \(\diff{(x)}{t}\) for all the \texttt{x\_vars} and add the independent variable \texttt{t} to our resulting matrix so we have a function that takes the `parsed' equations and returns the new resulting equations. It also takes care of normalizing the denominator to follow the specifications of the algorithm in \cite{Hubert2013}.

We normalize the denominator by subtracting the first row of the denominator to all the rows of the numerator and denominator, thus ensuring that the numerator has at least a single non-variable term and thus being normalized.

Finally, with the output being a few separate matrices, the last step is to concatenate them together to achieve our desired ODE matrix \(K\).

Following this from the predator prey model we get:
\[
    K = \begin{pmatrix}
        -1 & 0 & -1 & 0  & 0  & 0  & 0 & 0  \\
        0  & 0 & 1  & 0  & 1  & 1  & 0 & 0  \\
        0  & 0 & 0  & 0  & 0  & 0  & 0 & 1  \\
        0  & 0 & 0  & 1  & 0  & 0  & 0 & 0  \\
        1  & 1 & 1  & 0  & 1  & 0  & 0 & 0  \\
        1  & 0 & 0  & -1 & -1 & -1 & 0 & -1 \\
        0  & 0 & 0  & 0  & 0  & 0  & 1 & 1  \\
        0  & 0 & 0  & 1  & 0  & 0  & 0 & 1  \\
        1  & 1 & 1  & 1  & 1  & 0  & 1 & 1
    \end{pmatrix}.
\]

Which is the matrix we need to move on to the next part of the algorithm.

\subsection{Getting Scaling Symmetries}

Getting the scaling symmetries is the next part of the algorithm. This step is simple to implement in Julia since we have already implemented the function for getting \textit{row} and \textit{column} Hermite Normal Forms and their transforms.

First we take the \textit{row} Hermite Normal Form and Hermite Transform of \(K\). In the example of the Predator-Prey model we get using the code:
\begin{lstlisting}
H, U = hnf_with_transform(K)
\end{lstlisting}

That:
\[
    H = \begin{pmatrix}
        1 & 0 & 0 & 0 & -1 & -1 & 0 & 0 \\
        0 & 1 & 0 & 0 & 1  & 0  & 0 & 0 \\
        0 & 0 & 1 & 0 & 1  & 1  & 0 & 0 \\
        0 & 0 & 0 & 1 & 0  & 0  & 0 & 0 \\
        0 & 0 & 0 & 0 & 0  & 0  & 1 & 0 \\
        0 & 0 & 0 & 0 & 0  & 0  & 0 & 1 \\
        0 & 0 & 0 & 0 & 0  & 0  & 0 & 0 \\
        0 & 0 & 0 & 0 & 0  & 0  & 0 & 0 \\
        0 & 0 & 0 & 0 & 0  & 0  & 0 & 0
    \end{pmatrix}.
\]

And that:
\[
    U = \begin{pmatrix}
        0 & 0  & 0 & 0  & 0 & 0  & 1  & 1  & 0  \\
        0 & -1 & 0 & -1 & 0 & -1 & -1 & -1 & 1  \\
        0 & 1  & 0 & 0  & 0 & 0  & 0  & 0  & 0  \\
        0 & 0  & 0 & 1  & 0 & 0  & 0  & 0  & 0  \\
        0 & 0  & 0 & 1  & 0 & 1  & 0  & -1 & 0  \\
        0 & 0  & 0 & -1 & 0 & 0  & 0  & 1  & 0  \\
        1 & 1  & 0 & 0  & 0 & 0  & 1  & 1  & 0  \\
        0 & 0  & 1 & 1  & 0 & 0  & 0  & -1 & 0  \\
        0 & 0  & 0 & 0  & 1 & 1  & 0  & 0  & -1
    \end{pmatrix}.
\]

We see here that \(H\) has \(3\) zero rows so this means that \(r = 3\). Thus we set \(A\) to be the last \(3\) rows of \(U\) and we get that:
\[
    A = \begin{pmatrix}
        1 & 1 & 0 & 0 & 0 & 0 & 1 & 1  & 0  \\
        0 & 0 & 1 & 1 & 0 & 0 & 0 & -1 & 0  \\
        0 & 0 & 0 & 0 & 1 & 1 & 0 & 0  & -1
    \end{pmatrix}.
\]

Here \(A\) is our scaling symmetry matrix.

\subsection{Getting our Normal Hermite Transforms}

This step is simple. We set \(V\) to be the Hermite Normal Transform of \(A\) and \(W\) to be the inverse of \(V\). The code is simply as such:
\begin{lstlisting}
_, V = hnf_with_normal_transform_column(A)
\end{lstlisting}

We get that:
\[
    V = \begin{pmatrix}
        1 & 0 & 0 & -1 & 0  & 0  & -1 & -1 & 0 \\
        0 & 0 & 0 & 1  & 0  & 0  & 0  & 0  & 0 \\
        0 & 1 & 0 & 0  & -1 & 0  & 0  & 1  & 0 \\
        0 & 0 & 0 & 0  & 1  & 0  & 0  & 0  & 0 \\
        0 & 0 & 1 & 0  & 0  & -1 & 0  & 0  & 1 \\
        0 & 0 & 0 & 0  & 0  & 1  & 0  & 0  & 0 \\
        0 & 0 & 0 & 0  & 0  & 0  & 1  & 0  & 0 \\
        0 & 0 & 0 & 0  & 0  & 0  & 0  & 1  & 0 \\
        0 & 0 & 0 & 0  & 0  & 0  & 0  & 0  & 1
    \end{pmatrix}.
\]

And:
\[
    W = \begin{pmatrix}
        1 & 1 & 0 & 0 & 0 & 0 & 1 & 1  & 0  \\
        0 & 0 & 1 & 1 & 0 & 0 & 0 & -1 & 0  \\
        0 & 0 & 0 & 0 & 1 & 1 & 0 & 0  & -1 \\
        0 & 1 & 0 & 0 & 0 & 0 & 0 & 0  & 0  \\
        0 & 0 & 0 & 1 & 0 & 0 & 0 & 0  & 0  \\
        0 & 0 & 0 & 0 & 0 & 1 & 0 & 0  & 0  \\
        0 & 0 & 0 & 0 & 0 & 0 & 1 & 0  & 0  \\
        0 & 0 & 0 & 0 & 0 & 0 & 0 & 1  & 0  \\
        0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  & 1
    \end{pmatrix}.
\]

We then care about \(V_{\mathfrak{n}}\) and \(W_{\mathfrak{d}}\) which are the last \(n - r\) columns and rows respectively of \(V\) and \(W\). So in this case:
\[
    V_{\mathfrak{n}} = \begin{pmatrix}
        -1 & 0  & 0  & -1 & -1 & 0 \\
        1  & 0  & 0  & 0  & 0  & 0 \\
        0  & -1 & 0  & 0  & 1  & 0 \\
        0  & 1  & 0  & 0  & 0  & 0 \\
        0  & 0  & -1 & 0  & 0  & 1 \\
        0  & 0  & 1  & 0  & 0  & 0 \\
        0  & 0  & 0  & 1  & 0  & 0 \\
        0  & 0  & 0  & 0  & 1  & 0 \\
        0  & 0  & 0  & 0  & 0  & 1
    \end{pmatrix}.
\]

And:
\[
    W_{\mathfrak{n}} = \begin{pmatrix}
        0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
    \end{pmatrix}.
\]

\subsection{Putting Everything Together}

The final part of the algorithm is to use section 6.2 of \cite{Hubert2013}. What we do here in Julia is to create a new destination PolynomialRing for the new reparametrized ODE. We focus on equation (16) of the paper which is:
\[
    \diff{y}{t} = y \star F(y^{W_{\mathfrak{d}}}) \cdot V_{\mathfrak{n}}.
\]

In order to use this equation we need to get the \(\mathbb{R}^n \to \mathbb{R}^n\) function \(F\). To do this we use the definition that \(\diff{z}{t} = z \star F(z)\), where \(z\) is a vector of all the variables in the ODE to see find that with:
\[
    \diff{z}{t} =
    \begin{pmatrix}
        \diff{K}{t} \\
        \diff{d}{t} \\
        \diff{h}{t} \\
        \diff{k}{t} \\
        \diff{r}{t} \\
        \diff{s}{t} \\
        \diff{n}{t} \\
        \diff{p}{t} \\
        \diff{t}{t}
    \end{pmatrix} =
    \begin{pmatrix}
        0                                           \\
        0                                           \\
        0                                           \\
        0                                           \\
        0                                           \\
        0                                           \\
        0                                           \\
        n (r (1 - \frac{n}{K} - k \frac{p}{n + d})) \\
        sp (1 - h \frac{p}{n})                      \\
        1
    \end{pmatrix}.
\]

So
\[
    F(z) =
    \begin{pmatrix}
        0                                       \\
        0                                       \\
        0                                       \\
        0                                       \\
        0                                       \\
        0                                       \\
        0                                       \\
        r (1 - \frac{n}{K} - k \frac{p}{n + d}) \\
        s(1 - h \frac{p}{n})                    \\
        \frac{1}{t}
    \end{pmatrix}
\]

With us knowing what \(F\) is, all that is left to do is to put all of this into Julia code and we are left with a function that takes in the ode, \(V_{\mathfrak{n}}\) and \(W_{\mathfrak{d}}\) and that outputs the new parameterizations of the ode.
\begin{lstlisting}
prop_6_2(ode, V_n, W_d)
\end{lstlisting}

Running this code gives us the new reparameterization of the ODE which is:

\begin{align*}
    \diff{y_1}{t} & = 0                                                                    \\
    \diff{y_2}{t} & = 0                                                                    \\
    \diff{y_3}{t} & = 0                                                                    \\
    \diff{y_4}{t} & = \frac{-y_1 y_4^2 + y_1 y_4 - y_2 y_4 y_6 - y_4^3 + y_4^2}{y_1 + y_4} \\
    \diff{y_5}{t} & = \frac{y_3 y_4 y_5 - y_3 y_5^2}{y_4}                                  \\
    \diff{y_6}{t} & = 1
\end{align*}

In order to see what each original variable corresponds to in terms of the new variables, we can look at the matrix \(W_{\mathfrak{d}}\). The rows correspond to the original parameters (in this case \(K, d, \dots, p, t\) and the columns representing the power of the new parameters \(y_1, \dots\). So for example in this case:

We have the substitution from:
\[
    K \mapsto 1, \qquad d \mapsto y_1, \qquad h \mapsto 1, \qquad k \mapsto y_2, \qquad r \mapsto 1, \qquad s \mapsto y_3, \qquad n \mapsto y_3, \qquad p \mapsto y_5, \qquad t \mapsto y_6
\]

\section{Full Example}

This section gives another example with the full workthrough of the algorithm.

Let us say that we are working with the Verhulst Model of Logistic growth, defined by the differential equation given by:
\[
    \diff{n}{t} = rn \left( 1 - \frac{n}{k} \right).
\]

We start by obtaining the Luarent Polynomial from this equation. By multiplying the right side by \(t\) and \(\frac{1}{n}\) we get that the Laurent Polynomial of this equation is:
\[
    r t - r k^{-1} n.
\]

We can turn this polynomial into Julia code very straightforwardly with the code
\begin{lstlisting}
ode_verhulst = @ODEmodel(
    n'(t) = r * n * (1 - n / k),
)
\end{lstlisting}

We then following the use of the function that we implemented and previously explained \texttt{ode\_to\_matrix}. This function allows us to extract a matrix that describes the equation. We get the result, with variable order \texttt{k, r, n, t}, to be:
\[
    \begin{pmatrix}
        -1 & 0 \\
        1  & 0 \\
        1  & 1 \\
        1  & 1
    \end{pmatrix}
\]

Using Proposition 5.1 from \cite{Hubert2013} we can use this matrix to determine the matrix for the scaling symmetries of our system. We recall that this means we start by finding the \textit{row} Hermite Normal Form of \(K\) and a corresponding Hermite Multiplier.

To do this we use the \texttt{hnf\_with\_transform} from Nemo \cite{nemo}, which gives us the resulting \textit{row} Hermite Normal Form of \(K\):
\[
    H = \begin{pmatrix}
        1 & 0 \\
        0 & 1 \\
        0 & 0 \\
        0 & 0
    \end{pmatrix}
\]

And a corresponding Hermite Multiplier:
\[
    U = \begin{pmatrix}
        -1 & 0  & 0 & 0 \\
        1  & 1  & 0 & 0 \\
        1  & 0  & 1 & 0 \\
        0  & -1 & 0 & 1
    \end{pmatrix}
\]

Proposition 5.1 tells us that we look at the number of zero rows of \(H\), which we call \(r\). In this case \(r = 2\). then taking the last \(r\) rows of \(U\) gives us the matrix \(A\) which gives us a matrix that describes the scaling symmetries of the system.
\[
    A = \begin{pmatrix}
        1 & 0  & 1 & 0 \\
        0 & -1 & 0 & 1
    \end{pmatrix}
\]

The final step here is to get the \textit{column} Hermite Normal Form of \(A\), which is used to determine the new system. Using the new \texttt{hnf\_with\_normal\_transform\_column} function that we implemented earlier, we can find that our Normal Hermite Multiplier is:
\[
    V = \begin{pmatrix}
        1 & 0  & -1 & 0 \\
        0 & -1 & 0  & 1 \\
        0 & 0  & 1  & 0 \\
        0 & 0  & 0  & 1
    \end{pmatrix}
\]

We then can easily find its inverse \(W\) to be \(V^{-1}\), so:
\[
    W = \begin{pmatrix}
        1 & 0  & 1 & 0 \\
        0 & -1 & 0 & 1 \\
        0 & 0  & 1 & 0 \\
        0 & 0  & 0 & 1
    \end{pmatrix}
\]

Now that we have these matrices, what is left to do is to follow the last steps of the algorithm to get our new ODE model.

The last steps of the algorithm require us to split \(V\) into \(V_{\mathfrak{i}}\) and \(V_{\mathfrak{n}}\). Again following the algorithm in \cite{Hubert2013}, \(V_{\mathfrak{i}}\) is the first \(r\) columns of \(V\) and \(V_{\mathfrak{n}}\) is the last \(n - r\) columns of \(V\). Since \(r = 2\) in our example, we get that:
\[
    V_{\mathfrak{i}} = \begin{pmatrix}
        1 & 0  \\
        0 & -1 \\
        0 & 0  \\
        0 & 0
    \end{pmatrix}
\]

and that:
\[
    V_{\mathfrak{n}} = \begin{pmatrix}
        -1 & 0 \\
        0  & 1 \\
        1  & 0 \\
        0  & 1
    \end{pmatrix}.
\]

Similarly, \(W\) is split into \(W_{\mathfrak{u}}\) and \(W_{\mathfrak{d}}\), where \(W_{\mathfrak{u}}\) is the first \(r\) rows of \(W\) and \(W_{\mathfrak{d}}\) is the last \(n - r\) rows of \(W\). In this example we therefore have that:
\[
    W_{\mathfrak{u}} = \begin{pmatrix}
        1 & 0  & 1 & 0 \\
        0 & -1 & 0 & 1
    \end{pmatrix}.
\]

and that:
\[
    W_{\mathfrak{d}} = \begin{pmatrix}
        0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 1
    \end{pmatrix}.
\]

The matrices we care about here are \(V_{\mathfrak{n}}\) and \(W_{\mathfrak{d}}\). We will then use Proposition 6.2 from \cite{Hubert2013} in order to get our result. This proposition gives us the formula, that our new reparametrized ODE will be:
\[
    \diff{y}{t} \star F(y^{W_{\mathfrak{n}}}) \cdot V_{\mathfrak{n}}
\]

First we have to define what \(F\) defines here. We have that \(\diff{z}{t} = z\star F(z)\), where \(z\) is a vector of all the variables in the ODE, so in this example \(z = \begin{pmatrix} k & r & n & t \end{pmatrix}\). So:
\begin{align*}
    \diff{z}{t}
     & = \begin{pmatrix}
             \diff{k}{t} & \diff{r}{t} & \diff{n}{t} & \diff{t}{t}
         \end{pmatrix} \\
     & = \begin{pmatrix}
             0 & 0 & \frac{rnk - rn^2}{k} & 1 \\
         \end{pmatrix}
\end{align*}

Therefore, we have that:
\[
    F(z) = \begin{pmatrix}
        0 & 0 & \frac{rk - rn}{k} & \frac{1}{t}
    \end{pmatrix}
\]

We have that our new parameters, which are in the vector \(y\) are going to be \(n - r\) in number. Since in this example \(n = 4\) and \(r = 2\). We have that:
\[
    y = \begin{pmatrix}
        y_1 & y_2
    \end{pmatrix}
\]

We then take \(y^{W_{\mathfrak{d}}}\). The definition of how to take a vector of polynomials to the power of a matrix is explained in section 3.1. So we have that:
\begin{align*}
    y^{W_{\mathfrak{d}}}
     & = \begin{pmatrix}
             y_1 & y_2
         \end{pmatrix}^{
    \begin{pmatrix}
        0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 1
    \end{pmatrix}}                                             \\
     & = \begin{pmatrix}
             y_1^0 y_2^0 & y_1^0 y_2^0 & y_1^1 y_2^0 & y_1^0 y_2^1
         \end{pmatrix} \\
     & = \begin{pmatrix}
             1 & 1 & y_1 & y_2
         \end{pmatrix}
\end{align*}

We then have to take \(F(y^{W_{\mathfrak{d}}})\). Since our variable order is \(n, k, r, t\),
\begin{align*}
    F(y^{W_{\mathfrak{d}}})
     & = F(\begin{pmatrix}
               1 & 1 & y_1 & y_2
           \end{pmatrix})             \\
     & = \begin{pmatrix}
             0 & 0 & 1 - y_1 & \frac{1}{y_2}
         \end{pmatrix}
\end{align*}

Now, \(F(y^{W_{\mathfrak{d}}}) \cdot V_{\mathfrak{n}}\):
\[
    F(y^{W_{\mathfrak{d}}}) \cdot V_{\mathfrak{n}} =
    \begin{pmatrix}
        1 - y_1 & \frac{1}{y_2}
    \end{pmatrix}
\]

Then the final result we get that
\begin{align*}
    \diff{y}{t}
     & = y \star (F(y^{W_{\mathfrak{d}}}) \cdot V_{\mathfrak{n}}) \\
     & = \begin{pmatrix} y_1 - y_1^2 & 1 \end{pmatrix}
\end{align*}

With this we can conclude and get our final new reparametrized differential equation to be:
\begin{align*}
    \diff{y_1}{t} & = y_1 - y_1^2 \\
    \diff{y_2}{t} & = 1
\end{align*}

Which as we can tell is much simpler than the equation we had in the beginning.

Finally we can look at how the substitution looks by looking at \(W_{\mathfrak{d}}\). In this case:
\[
    k \mapsto 1, \qquad r \mapsto 1, \qquad n \mapsto y_1, \qquad t \mapsto y_2.
\]

\section{Conclusion}

In this thesis, we implemented a novel methodology for the reparameterization of ordinary differential equation (ODE) models by using the scaling invariants and symmetry reductions. The approach, based on the algorithm by Hubert and Labahn \cite{Hubert2013}, has been implemented through the Julia programming language.

\section{Potential Improvements}

The algorithm that we implemented, while reducing the number of parameters in the system, does have some flaws when it comes to by how much it reduces

\newpage
\bibliographystyle{plain}
\bibliography{main}

% \newpage
% \appendix

% \section{Appendix}
% \label{sec:appendix}

\end{document}
